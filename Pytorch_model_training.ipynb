{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c2ac27-9c5a-4469-b066-d5f82ede2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install feature-engine\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b5951e-06af-48b5-8ac8-3d8cbd698415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import xgboost as xg\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from feature_engine.encoding import OneHotEncoder as fe_OneHotEncoder\n",
    "\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdd53d4-9324-4735-b23d-574a1ac0bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('../wids_datathon2023/train_data.csv', parse_dates=[\"startdate\"])\n",
    "test_raw = pd.read_csv('../wids_datathon2023/test_data.csv', parse_dates=[\"startdate\"])\n",
    "submit = pd.read_csv('../wids_datathon2023/sample_solution.csv')\n",
    "target = 'contest-tmp2m-14d__tmp2m'\n",
    "TARGET = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a7f9c6-b517-4db4-92c9-95d8a9ce5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    return mean_squared_error(actual, predicted, squared=False)\n",
    "\n",
    "def location_nom(train, test):\n",
    "    scale = 14\n",
    "\n",
    "    train.loc[:,'lat']=round(train.lat,scale)\n",
    "    train.loc[:,'lon']=round(train.lon,scale)\n",
    "    test.loc[:,'lat']=round(test.lat,scale)\n",
    "    test.loc[:,'lon']=round(test.lon,scale)\n",
    "\n",
    "    all_df = pd.concat([train, test], axis=0)\n",
    "    all_df['loc_group'] = all_df.groupby(['lat','lon']).ngroup()\n",
    "    train = all_df.iloc[:len(train)]\n",
    "    test = all_df.iloc[len(train):].drop(target, axis=1)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def categorical_encode(train, test):\n",
    "    le = LabelEncoder()\n",
    "    train['climateregions__climateregion'] = le.fit_transform(train['climateregions__climateregion'])\n",
    "    test['climateregions__climateregion'] = le.transform(test['climateregions__climateregion'])\n",
    "    return train, test\n",
    "\n",
    "def one_hot_categorical_encode(train, test):\n",
    "    ohe_enc = fe_OneHotEncoder(\n",
    "    top_categories=None,\n",
    "    variables=['climateregions__climateregion'],  # we can select which variables to encode\n",
    "    drop_last=True)  # to return k-1, false to return k\n",
    "    \n",
    "    ohe_enc.fit(train)\n",
    "    train = ohe_enc.transform(train)\n",
    "    test = ohe_enc.transform(test)\n",
    "    return train, test\n",
    "    \n",
    "def creat_new_featute(df):\n",
    "    df['year'] = df['startdate'].dt.year\n",
    "    df['month'] = df['startdate'].dt.month\n",
    "    df['day_of_year'] = df['startdate'].dt.dayofyear\n",
    "    return df\n",
    "\n",
    "def filter_na_cols(df):\n",
    "    count_na_df = df.isna().sum() \n",
    "    if count_na_df[count_na_df > 0].tolist():\n",
    "        return count_na_df[count_na_df > 0]\n",
    "    else:\n",
    "        return 'Clean dataset'\n",
    "\n",
    "\n",
    "def feature_engineering_tabnet(train_raw, test_raw):\n",
    "    train, test = location_nom(train_raw, test_raw)\n",
    "    train = creat_new_featute(train)\n",
    "    test = creat_new_featute(test)\n",
    "    drop_cols = ['index', 'startdate', 'lat', 'lon', target]\n",
    "    features = [col for col in train.columns if col not in drop_cols]\n",
    "    X = train[features]\n",
    "    X_test = test[features]\n",
    "    y = train[target]\n",
    "    \n",
    "\n",
    "    return X, y, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896613a9-2513-4990-88c7-e707f2526ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_test = feature_engineering_tabnet(train_raw.copy(), test_raw.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32633c6-f109-42ce-92b8-60b6b94bc657",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_na = [\n",
    "    'nmme0-tmp2m-34w__ccsm30', \n",
    "    'nmme-tmp2m-56w__ccsm3', \n",
    "    'nmme-prate-34w__ccsm3', \n",
    "    'nmme0-prate-56w__ccsm30', \n",
    "    'nmme0-prate-34w__ccsm30', \n",
    "    'nmme-prate-56w__ccsm3', \n",
    "    'nmme-tmp2m-34w__ccsm3']\n",
    "\n",
    "g_means =  ['nmme0-tmp2m-34w__nmme0mean', \n",
    " 'nmme-tmp2m-56w__nmmemean', \n",
    " 'nmme-prate-34w__nmmemean', \n",
    " 'nmme0-prate-56w__nmme0mean', \n",
    " 'nmme0-prate-34w__nmme0mean', \n",
    " 'nmme-prate-56w__nmmemean', \n",
    " 'nmme-tmp2m-34w__nmmemean']\n",
    "\n",
    "\n",
    "g_1 = ['nmme0-tmp2m-34w__cancm30',\n",
    "'nmme0-tmp2m-34w__cancm40',\n",
    "'nmme0-tmp2m-34w__ccsm40',\n",
    "'nmme0-tmp2m-34w__cfsv20',\n",
    "'nmme0-tmp2m-34w__gfdlflora0',\n",
    "'nmme0-tmp2m-34w__gfdlflorb0',\n",
    "'nmme0-tmp2m-34w__gfdl0',\n",
    "'nmme0-tmp2m-34w__nasa0']\n",
    "\n",
    "g_2 = ['nmme-tmp2m-56w__cancm3',\n",
    "'nmme-tmp2m-56w__cancm4',\n",
    "'nmme-tmp2m-56w__ccsm4',\n",
    "'nmme-tmp2m-56w__cfsv2',\n",
    "'nmme-tmp2m-56w__gfdl',\n",
    "'nmme-tmp2m-56w__gfdlflora',\n",
    "'nmme-tmp2m-56w__gfdlflorb',\n",
    "'nmme-tmp2m-56w__nasa']\n",
    "\n",
    "g_3 = ['nmme-prate-34w__cancm3',\n",
    "'nmme-prate-34w__cancm4',\n",
    "'nmme-prate-34w__ccsm4',\n",
    "'nmme-prate-34w__cfsv2',\n",
    "'nmme-prate-34w__gfdl',\n",
    "'nmme-prate-34w__gfdlflora',\n",
    "'nmme-prate-34w__gfdlflorb',\n",
    "'nmme-prate-34w__nasa']\n",
    "\n",
    "g_4 = [ 'nmme0-prate-56w__cancm30',\n",
    "'nmme0-prate-56w__cancm40',\n",
    "'nmme0-prate-56w__ccsm40',\n",
    "'nmme0-prate-56w__cfsv20',\n",
    "'nmme0-prate-56w__gfdlflora0',\n",
    "'nmme0-prate-56w__gfdlflorb0',\n",
    "'nmme0-prate-56w__gfdl0',\n",
    "'nmme0-prate-56w__nasa0']\n",
    "\n",
    "g_5 = ['nmme0-prate-34w__cancm30',\n",
    "'nmme0-prate-34w__cancm40',\n",
    "'nmme0-prate-34w__ccsm40',\n",
    "'nmme0-prate-34w__cfsv20',\n",
    "'nmme0-prate-34w__gfdlflora0',\n",
    "'nmme0-prate-34w__gfdlflorb0',\n",
    "'nmme0-prate-34w__gfdl0',\n",
    "'nmme0-prate-34w__nasa0']\n",
    "\n",
    "g_6 = ['nmme-prate-56w__cancm3',\n",
    "'nmme-prate-56w__cancm4',\n",
    "'nmme-prate-56w__ccsm4',\n",
    "'nmme-prate-56w__cfsv2',\n",
    "'nmme-prate-56w__gfdl',\n",
    "'nmme-prate-56w__gfdlflora',\n",
    "'nmme-prate-56w__gfdlflorb',\n",
    "'nmme-prate-56w__nasa']\n",
    "\n",
    "g_7 = ['nmme-tmp2m-34w__cancm3',\n",
    "'nmme-tmp2m-34w__cancm4',\n",
    "'nmme-tmp2m-34w__ccsm4',\n",
    "'nmme-tmp2m-34w__cfsv2',\n",
    "'nmme-tmp2m-34w__gfdl',\n",
    "'nmme-tmp2m-34w__gfdlflora',\n",
    "'nmme-tmp2m-34w__gfdlflorb',\n",
    "'nmme-tmp2m-34w__nasa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1129dd2-4fc1-4f5a-8e89-02db83483d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean dataset'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = [g_1, g_2, g_3, g_4, g_5, g_6, g_7]\n",
    "\n",
    "zip_cols = zip(col_na, gs, g_means)\n",
    "for c, g, m in (zip_cols):\n",
    "    X[c] = (X[m]*9) - X[g].sum(1)\n",
    "X['ccsm30'] = 9*X['nmme0mean'] - (X['cancm30']+X['cancm40']+X['ccsm40']+X['cfsv20']+X['gfdlflora0']+X['gfdlflorb0']+X['gfdl0']+X['nasa0'])\n",
    "\n",
    "filter_na_cols(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad872bd-0275-46c4-9f03-9b18c9fd518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "X['YearsSinceRecordings'] = datetime.datetime.now().year - X.year\n",
    "X_test['YearsSinceRecordings'] = datetime.datetime.now().year - X_test.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88b605e-348f-4ea6-bff8-6d953eadcc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_correlated(df, threshold):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    reduced_corr_matrix = corr_matrix.mask(mask)\n",
    "    features_to_drop = [c for c in reduced_corr_matrix.columns if any(reduced_corr_matrix[c] > threshold)]\n",
    "    return features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9fad1d-de25-4611-929f-f18ad7f5ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = identify_correlated(X, .80)\n",
    "X_reduced = pd.DataFrame(X.drop(features_to_drop, axis=1))\n",
    "X_test_reduced = pd.DataFrame(X_test.drop(features_to_drop, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405ed6a0-f2f5-4bd6-a4be-3f05f223ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    #os.environ['CUDA_LAUNCH_BLOCKING'] = 1\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724794d9-caa3-44b7-895f-c570453ca242",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where((X_reduced.dtypes != np.float64))\n",
    "\n",
    "list_cols= list(X_reduced.columns)\n",
    "cat_cols = []\n",
    "for i in categorical_features_indices[0]:\n",
    "    cat_cols.append(list_cols[i])\n",
    "\n",
    "cont_cols = list(X_reduced.columns).copy()\n",
    "for col in cat_cols:\n",
    "    cont_cols.remove(col) \n",
    "\n",
    "train_cols = list(X_reduced.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1cf1e81-2b64-4865-b39a-fcf93b285732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['climateregions__climateregion',\n",
       " 'loc_group',\n",
       " 'day_of_year',\n",
       " 'YearsSinceRecordings']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2526d29-0609-4dc1-a364-e0687930c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_reduced,y],axis=1)\n",
    "test_df = X_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e9773b-5706-4a8e-b5e6-7429d203f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the index of train and val \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_reduced, y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_index = X_train.index\n",
    "val_index = X_val.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e813833-c14d-4ccb-a57d-109d266fd764",
   "metadata": {},
   "source": [
    "## Handling Continuos Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "443ad651-12cc-4caf-ab04-678b3843247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Scaling\n",
    "\n",
    "scaler = RobustScaler(quantile_range=(10.0, 90.0))\n",
    "scaler.fit(pd.concat([train_df[cont_cols], test_df[cont_cols]]))\n",
    "\n",
    "train_df[cont_cols] = scaler.transform(train_df[cont_cols].values)\n",
    "test_df[cont_cols] = scaler.transform(test_df[cont_cols].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ae79b4-f749-4040-b2d0-dcdb7e046915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train numerical tensor\n",
    "contTensor = np.stack([train_df[col] for col in cont_cols],axis=1)\n",
    "contTensor = torch.tensor(contTensor,dtype=torch.float)\n",
    "\n",
    "# test numerical tensor\n",
    "testcontTensor = np.stack([test_df[col] for col in cont_cols],axis=1)\n",
    "testcontTensor = torch.tensor(testcontTensor,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4be39-d2b2-4d95-9903-2071e80b9e1a",
   "metadata": {},
   "source": [
    "## Handling Categorical Features\n",
    "- Les embeddings en bas Just to see how it works (it will be handled in the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bdf53ff-a82b-4ceb-b175-2c1ebd1262e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train_df[col], test_df[col]]))\n",
    "    train_df[col] = le.transform(train_df[col].values)\n",
    "    test_df[col] = le.transform(test_df[col].values)\n",
    "    uniques[col] = len(pd.concat([train_df[col], test_df[col]], axis=0).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a5ddbf-358d-447f-9119-50bb0a7b20a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0, 243,   3],\n",
       "        [  0,   0, 244,   3],\n",
       "        [  0,   0, 245,   3],\n",
       "        ...,\n",
       "        [  9, 513, 241,   1],\n",
       "        [  9, 513, 242,   1],\n",
       "        [  9, 513, 243,   1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catTensor = np.stack([train_df[col] for col in cat_cols],1)\n",
    "catTensor = torch.tensor(catTensor,dtype=torch.int64)\n",
    "catTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f23a1727-649a-47a9-9f4c-8b490cfdbb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0, 304,   0],\n",
       "        [  0,   0, 305,   0],\n",
       "        [  0,   0, 306,   0],\n",
       "        ...,\n",
       "        [  9, 513, 362,   0],\n",
       "        [  9, 513, 363,   0],\n",
       "        [  9, 513, 364,   0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcatTensor = np.stack([test_df[col] for col in cat_cols],1)\n",
    "testcatTensor = torch.tensor(testcatTensor,dtype=torch.int64)\n",
    "testcatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1e02de-8357-492b-81fd-453bce1f76ad",
   "metadata": {},
   "source": [
    "-  **embeddings dims**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "275343b0-4f24-41b0-81ae-e134c678fa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 514, 365, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = list(uniques.values())\n",
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "931e63b4-e538-46ef-8e22-68ad16ac5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims =[(15,7),(514,180),(365,20),(4,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f1be8-d7f9-4ca2-ae5d-7abd3086f830",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38dad7d7-b224-46da-837b-2fedf31afa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=42)\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c37f65e-a3eb-4494-a7ff-58269d6d5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "class ModelWIDS2023(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_cont, out_sz, layers,device=device, drop=0.5):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        #Embedding layers\n",
    "        self.embed_repr = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dims])\n",
    "        self.embed_dropout = nn.Dropout(drop)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((val[1] for val in embedding_dim))\n",
    "        n_in = n_cont + n_emb\n",
    "        \n",
    "        # FastiAI approach: apply BN and dropout before relu\n",
    "        for layer in layers:\n",
    "            layerlist.append(nn.Linear(n_in,layer))\n",
    "            layerlist.append(nn.Dropout(drop))\n",
    "            #layerlist.append(nn.BatchNorm1d(layer))\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            n_in = layer\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        # Initialize weights in the two linear layers\n",
    "        for lin_layer in self.layers:\n",
    "            lin_layer.apply(init_weights)\n",
    "            #if type(lin_layer) == nn.Linear:\n",
    "                #nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "        \n",
    "    def forward(self, cat,cont):\n",
    "        cont = cont.to(self.device)\n",
    "        cat= cat.to(self.device)\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embed_repr):\n",
    "            embeddings.append(e(cat[:,i]))\n",
    "        x = torch.cat(embeddings,1)\n",
    "        x = self.embed_dropout(x)#: donne mieux sans ça\n",
    "        #x_cont = self.bn_cont(cont)\n",
    "        x = torch.cat([x,cont],1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0ddff46-5be9-42d8-bb1f-531b241b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWIDS2023(embedding_dims, len(cont_cols), 1, [512,256], drop=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc867b5a-50fa-4f48-974a-b8b94a1563ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelWIDS2023(\n",
       "  (embed_repr): ModuleList(\n",
       "    (0): Embedding(15, 7)\n",
       "    (1): Embedding(514, 180)\n",
       "    (2): Embedding(365, 20)\n",
       "    (3): Embedding(4, 3)\n",
       "  )\n",
       "  (embed_dropout): Dropout(p=0, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(142, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=352, out_features=512, bias=True)\n",
       "    (1): Dropout(p=0, inplace=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): Dropout(p=0, inplace=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42f9deac-f4b2-4b31-9879-d7cdd7b5d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = catTensor[train_index]\n",
    "val_cat = catTensor[val_index]\n",
    "\n",
    "train_cont = contTensor[train_index]\n",
    "val_cont = contTensor[val_index]\n",
    "\n",
    "y= torch.tensor(y,dtype=torch.float).reshape(-1,1)\n",
    "y_train = y[train_index]\n",
    "y_val = y[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0f28a02-1e3f-4fba-8237-1853799e92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c81c68c-4880-4f3b-b295-80e5e544cc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : 2.4576966762542725\n",
      "Epoch 100 : 1.0172197818756104\n",
      "Epoch 150 : 0.5955129265785217\n",
      "Epoch 200 : 0.4326685965061188\n",
      "Epoch 250 : 0.33958926796913147\n",
      "Epoch 300 : 0.34417739510536194\n",
      "Epoch 350 : 0.2858445346355438\n",
      "Epoch 400 : 0.26356828212738037\n",
      "Epoch 450 : 0.2457670420408249\n",
      "Epoch 500 : 0.22971747815608978\n",
      "Epoch 550 : 0.22052985429763794\n",
      "Epoch 600 : 0.21152520179748535\n",
      "Epoch 650 : 0.20356982946395874\n",
      "Epoch 700 : 0.19699883460998535\n",
      "Epoch 750 : 0.19086650013923645\n",
      "Epoch 800 : 0.18603746592998505\n",
      "Epoch 850 : 0.18127407133579254\n",
      "Epoch 900 : 0.1775096207857132\n",
      "Epoch 950 : 0.17375358939170837\n",
      "Epoch 1000 : 0.17074063420295715\n",
      "Epoch 1050 : 0.16767717897891998\n",
      "Epoch 1100 : 0.1652105748653412\n",
      "Epoch 1150 : 0.16234055161476135\n",
      "Epoch 1200 : 0.16008633375167847\n",
      "Epoch 1250 : 0.1579250544309616\n",
      "Epoch 1300 : 0.15586405992507935\n",
      "Epoch 1350 : 0.15403179824352264\n",
      "Epoch 1400 : 0.15224039554595947\n",
      "Epoch 1450 : 0.1504911482334137\n",
      "Epoch 1500 : 0.14901253581047058\n",
      "Epoch 1550 : 0.1473817229270935\n",
      "Epoch 1600 : 0.14607425034046173\n",
      "Epoch 1650 : 0.14463020861148834\n",
      "Epoch 1700 : 0.14328289031982422\n",
      "Epoch 1750 : 0.14205996692180634\n",
      "Epoch 1800 : 0.141042560338974\n",
      "Epoch 1850 : 0.1396189033985138\n",
      "Epoch 1900 : 0.13857883214950562\n",
      "Epoch 1950 : 0.13764476776123047\n",
      "Epoch 2000 : 0.13660378754138947\n",
      "Epoch 2050 : 0.13556843996047974\n",
      "Epoch 2100 : 0.13463927805423737\n",
      "Epoch 2150 : 0.13361740112304688\n",
      "Epoch 2200 : 0.13287033140659332\n",
      "Epoch 2250 : 0.1320154070854187\n",
      "Epoch 2300 : 0.13111035525798798\n",
      "Epoch 2350 : 0.13046064972877502\n",
      "Epoch 2400 : 0.1296440064907074\n",
      "Epoch 2450 : 0.12906642258167267\n",
      "Epoch 2500 : 0.12820032238960266\n",
      "Epoch 2550 : 0.12748198211193085\n",
      "Epoch 2600 : 0.12673406302928925\n",
      "Epoch 2650 : 0.12611797451972961\n",
      "Epoch 2700 : 0.12530270218849182\n",
      "Epoch 2750 : 0.12472951412200928\n",
      "Epoch 2800 : 0.12406214326620102\n",
      "Epoch 2850 : 0.12355844676494598\n",
      "Epoch 2900 : 0.12299703806638718\n",
      "Epoch 2950 : 0.12243760377168655\n",
      "Epoch 3000 : 0.12187506258487701\n",
      "Epoch 3050 : 0.12114015221595764\n",
      "Epoch 3100 : 0.12059537321329117\n",
      "Epoch 3150 : 0.12021906673908234\n",
      "Epoch 3200 : 0.11952966451644897\n",
      "Epoch 3250 : 0.11904878914356232\n",
      "Epoch 3300 : 0.11865538358688354\n",
      "Epoch 3350 : 0.1179630309343338\n",
      "Epoch 3400 : 0.11763817071914673\n",
      "Epoch 3450 : 0.1172935888171196\n",
      "Epoch 3500 : 0.11659017950296402\n",
      "Epoch 3550 : 0.11613031476736069\n",
      "Epoch 3600 : 0.11589246243238449\n",
      "Epoch 3650 : 0.11527881026268005\n",
      "Epoch 3700 : 0.11474597454071045\n",
      "Epoch 3750 : 0.11449962109327316\n",
      "Epoch 3800 : 0.11410710960626602\n",
      "Epoch 3850 : 0.11364774405956268\n",
      "Epoch 3900 : 0.11327726393938065\n",
      "Epoch 3950 : 0.11269498616456985\n",
      "Epoch 4000 : 0.11240432411432266\n",
      "Epoch 4050 : 0.1120663583278656\n",
      "Epoch 4100 : 0.11183604598045349\n",
      "Epoch 4150 : 0.1113298311829567\n",
      "Epoch 4200 : 0.11125931888818741\n",
      "Epoch 4250 : 0.11060214787721634\n",
      "Epoch 4300 : 0.11026842892169952\n",
      "Epoch 4350 : 0.10975957661867142\n",
      "Epoch 4400 : 0.10958543419837952\n",
      "Epoch 4450 : 0.10943762212991714\n",
      "Epoch 4500 : 0.10878274589776993\n",
      "Epoch 4550 : 0.10855389386415482\n",
      "Epoch 4600 : 0.1082717552781105\n",
      "Epoch 4650 : 0.10795505344867706\n",
      "Epoch 4700 : 0.10762602090835571\n",
      "Epoch 4750 : 0.1074913740158081\n",
      "Epoch 4800 : 0.10714082419872284\n",
      "Epoch 4850 : 0.10668054223060608\n",
      "Epoch 4900 : 0.10658688843250275\n",
      "Epoch 4950 : 0.10607820004224777\n",
      "Epoch 5000 : 0.1058141216635704\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model.forward(train_cat,train_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred,y_train.to(device)))\n",
    "    losses.append(loss)\n",
    "    if i%50 == 0:\n",
    "        print(f\"Epoch {i} : {loss}\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4157898e-e182-4196-9b35-b72d4640a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.16021375358104706\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred=model(val_cat,val_cont)\n",
    "    loss=torch.sqrt(loss_function(y_pred,y_val.to(device)))\n",
    "print('RMSE: {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e7c0c54-5f59-4d0e-9971-8e78c3aab0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.490929 , 29.633265 , 29.680397 , ...,  7.216925 ,  7.8647537,\n",
       "        8.159615 ], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat = testcatTensor\n",
    "test_cont = testcontTensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds_test=model(test_cat,test_cont)\n",
    "\n",
    "preds_test = preds_test.detach().cpu().numpy().flatten()\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f985f-5aa7-4068-9346-e259ccb947c8",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef8d74e4-f260-46c3-a0a7-54f86db42a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = f\"../Pytorch&Keras/modelpytorch_3_nn.pt\"\n",
    "torch.save(model, model_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccb800db-a43f-407a-add1-25c3cfa83781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.490929 , 29.633265 , 29.680397 , ...,  7.216925 ,  7.8647537,\n",
       "        8.159615 ], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jsut for verification\n",
    "model_root = f\"../Pytorch&Keras/models_pytorch/modelpytorch_3_nn.pt\"\n",
    "\n",
    "model_final = torch.load(model_root)\n",
    "with torch.no_grad():\n",
    "    test_cat = testcatTensor\n",
    "    test_cont = testcontTensor\n",
    "    preds_test_verif=model_final(test_cat,test_cont)\n",
    "pred_test = preds_test_verif.detach().cpu().numpy().flatten()\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4569c5eb-8d4a-453c-b12f-f167dd66c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[target] = pred_test\n",
    "submit.to_csv('../pytorch_model_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f9fa0e2-1c8d-48ae-a60e-fc4777fc9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last submission (that gave us 0.627)\n",
    "best627 = pd.read_csv('../fast_ai_regression/submissions_with_fast_ai/(0.627)sub631_0.9_fastaufeat0.1.csv')[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f22a9-0361-4bbb-b7de-d87f937fad1d",
   "metadata": {},
   "source": [
    "## PsuedoLabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff8a932d-4aa5-477f-976a-034c31466686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = torch.load('../Pytorch&Keras/modelpytorch_3_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73fadeaa-215b-40fc-a1e1-9a5acea37bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.490929 , 29.633265 , 29.680397 , ...,  7.216925 ,  7.8647537,\n",
       "        8.159615 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    preds_test_verif=model_best(test_cat,test_cont)\n",
    "pred_test = preds_test_verif.detach().cpu().numpy().flatten()\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8fefe-6c4c-4b98-bfbb-5b906646dfdd",
   "metadata": {},
   "source": [
    "- **Concatenate all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d7f6a7a-2244-4750-ab1e-96cd1ebf4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = torch.tensor(preds_test,dtype=torch.float).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29b1f9ed-045e-4c5d-8b37-85a2c39e090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot_cat = torch.cat([train_cat,val_cat,test_cat],0)\n",
    "X_tot_cont = torch.cat([train_cont, val_cont,test_cont],0)\n",
    "y_tot = torch.cat([y_train, y_val,y_test],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebfc68fa-f436-4271-9c7b-11b6907493eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr =0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6b57986-576c-41ed-a1f4-82cb51931ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : 0.13922029733657837\n",
      "Epoch 100 : 0.11930844187736511\n",
      "Epoch 150 : 0.11668518930673599\n",
      "Epoch 200 : 0.1156155988574028\n",
      "Epoch 250 : 0.11458556354045868\n",
      "Epoch 300 : 0.1154228076338768\n",
      "Epoch 350 : 0.11320791393518448\n",
      "Epoch 400 : 0.11238934844732285\n",
      "Epoch 450 : 0.11118602752685547\n",
      "Epoch 500 : 0.11137665808200836\n",
      "Epoch 550 : 0.11074534058570862\n",
      "Epoch 600 : 0.11011864244937897\n",
      "Epoch 650 : 0.10966353118419647\n",
      "Epoch 700 : 0.10936149954795837\n",
      "Epoch 750 : 0.10916829854249954\n",
      "Epoch 800 : 0.10849349945783615\n",
      "Epoch 850 : 0.10806155204772949\n",
      "Epoch 900 : 0.10755898803472519\n",
      "Epoch 950 : 0.10746560245752335\n",
      "Epoch 1000 : 0.10655444115400314\n",
      "Epoch 1050 : 0.10678943246603012\n",
      "Epoch 1100 : 0.10588598996400833\n",
      "Epoch 1150 : 0.10601924359798431\n",
      "Epoch 1200 : 0.10552255809307098\n",
      "Epoch 1250 : 0.10542131215333939\n",
      "Epoch 1300 : 0.10500877350568771\n",
      "Epoch 1350 : 0.10489461570978165\n",
      "Epoch 1400 : 0.10443870723247528\n",
      "Epoch 1450 : 0.10396043956279755\n",
      "Epoch 1500 : 0.10385225713253021\n",
      "Epoch 1550 : 0.10387058556079865\n",
      "Epoch 1600 : 0.10334896296262741\n",
      "Epoch 1650 : 0.10310103744268417\n",
      "Epoch 1700 : 0.10302787274122238\n",
      "Epoch 1750 : 0.10267505794763565\n",
      "Epoch 1800 : 0.10224384069442749\n",
      "Epoch 1850 : 0.10214024037122726\n",
      "Epoch 1900 : 0.1021013855934143\n",
      "Epoch 1950 : 0.10151293128728867\n",
      "Epoch 2000 : 0.10133820027112961\n",
      "Epoch 2050 : 0.10130901634693146\n",
      "Epoch 2100 : 0.10082454234361649\n",
      "Epoch 2150 : 0.10064154863357544\n",
      "Epoch 2200 : 0.10058581829071045\n",
      "Epoch 2250 : 0.10018547624349594\n",
      "Epoch 2300 : 0.10032034665346146\n",
      "Epoch 2350 : 0.09989731013774872\n",
      "Epoch 2400 : 0.0997604951262474\n",
      "Epoch 2450 : 0.09961943328380585\n",
      "Epoch 2500 : 0.09931350499391556\n",
      "Epoch 2550 : 0.09912598133087158\n",
      "Epoch 2600 : 0.09909048676490784\n",
      "Epoch 2650 : 0.09877736121416092\n",
      "Epoch 2700 : 0.0984746664762497\n",
      "Epoch 2750 : 0.09830152243375778\n",
      "Epoch 2800 : 0.09803654253482819\n",
      "Epoch 2850 : 0.09802040457725525\n",
      "Epoch 2900 : 0.09780532121658325\n",
      "Epoch 2950 : 0.09768430143594742\n",
      "Epoch 3000 : 0.09799298644065857\n",
      "Epoch 3050 : 0.09736975282430649\n",
      "Epoch 3100 : 0.09716939181089401\n",
      "Epoch 3150 : 0.09713352471590042\n",
      "Epoch 3200 : 0.09715662151575089\n",
      "Epoch 3250 : 0.09674040973186493\n",
      "Epoch 3300 : 0.09660898149013519\n",
      "Epoch 3350 : 0.09643570333719254\n",
      "Epoch 3400 : 0.09631253033876419\n",
      "Epoch 3450 : 0.09635531902313232\n",
      "Epoch 3500 : 0.09603644907474518\n",
      "Epoch 3550 : 0.09571131318807602\n",
      "Epoch 3600 : 0.09572327136993408\n",
      "Epoch 3650 : 0.09547920525074005\n",
      "Epoch 3700 : 0.09535960853099823\n",
      "Epoch 3750 : 0.09507587552070618\n",
      "Epoch 3800 : 0.09497188031673431\n",
      "Epoch 3850 : 0.09503348916769028\n",
      "Epoch 3900 : 0.09499114751815796\n",
      "Epoch 3950 : 0.09472370892763138\n",
      "Epoch 4000 : 0.09455607086420059\n",
      "Epoch 4050 : 0.09434546530246735\n",
      "Epoch 4100 : 0.09467580914497375\n",
      "Epoch 4150 : 0.09422461688518524\n",
      "Epoch 4200 : 0.09395652264356613\n",
      "Epoch 4250 : 0.09390611201524734\n",
      "Epoch 4300 : 0.09350349009037018\n",
      "Epoch 4350 : 0.09372247755527496\n",
      "Epoch 4400 : 0.09372569620609283\n",
      "Epoch 4450 : 0.09348253905773163\n",
      "Epoch 4500 : 0.09321670979261398\n",
      "Epoch 4550 : 0.09342025220394135\n",
      "Epoch 4600 : 0.09310909360647202\n",
      "Epoch 4650 : 0.09306436032056808\n",
      "Epoch 4700 : 0.09305737167596817\n",
      "Epoch 4750 : 0.09269064664840698\n",
      "Epoch 4800 : 0.09283029288053513\n",
      "Epoch 4850 : 0.09240106493234634\n",
      "Epoch 4900 : 0.09251370280981064\n",
      "Epoch 4950 : 0.09227636456489563\n",
      "Epoch 5000 : 0.09218419343233109\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model.forward(X_tot_cat,X_tot_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred,y_tot.to(device)))\n",
    "    losses.append(loss)\n",
    "    if i%50 == 0:\n",
    "        print(f\"Epoch {i} : {loss}\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb7e4d14-39a8-4b62-aec9-154531962344",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = f\"../Pytorch&Keras/modelpytorch_3_psuedo_nn.pt\"\n",
    "torch.save(model, model_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46eb290e-b11c-4959-9883-f9200ca9b017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.37088 , 29.50084 , 29.532034, ...,  7.125566,  7.762993,\n",
       "        8.086815], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    preds_test_pseudo = model(test_cat,test_cont)\n",
    "preds_test_pseudo = preds_test_pseudo.detach().cpu().numpy().flatten()\n",
    "preds_test_pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8c363d3-e7cf-4a2c-a419-c31faa344fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        29.262159\n",
       "1        29.270729\n",
       "2        29.290475\n",
       "3        29.348092\n",
       "4        29.413255\n",
       "           ...    \n",
       "31349     6.667905\n",
       "31350     6.859207\n",
       "31351     6.239443\n",
       "31352     7.044306\n",
       "31353     7.555243\n",
       "Name: contest-tmp2m-14d__tmp2m, Length: 31354, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.95*best627 +0.05*preds_test_pseudo # gives 0.622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bb5afb7-56c6-4b03-b872-5eac84c9ca23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.37088 , 29.50084 , 29.532034, ...,  7.125566,  7.762993,\n",
       "        8.086815], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just verification\n",
    "model_root = '../Pytorch&Keras/models_pytorch/modelpytorch_3_psuedo_nn.pt'\n",
    "\n",
    "model_final = torch.load(model_root)\n",
    "with torch.no_grad():\n",
    "    test_cat = testcatTensor\n",
    "    test_cont = testcontTensor\n",
    "    preds_test_verif=model_final(test_cat,test_cont)\n",
    "pred_test = preds_test_verif.detach().cpu().numpy().flatten()\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e00b0a41-4633-4716-9331-7bb0e84ed42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[target] = pred_test\n",
    "submit.to_csv('../pytorch_model_2_pseudo.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70d4603a-dd18-48d7-8be1-6ebf57f25720",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[target] = 0.95*best627 +0.05*preds_test_pseudo # gives 0.622\n",
    "submit.to_csv('../Pytorch&Keras/best627_0.95_pytorch_mod3pseudo_0.05.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7a8e5-de39-40a8-be7a-99294be3ec31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
